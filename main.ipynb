{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c6ba7c-abf0-4879-8daf-64cf03f708e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c conda-forge imbalanced-learn -y\n",
    "# ! pip install nose\n",
    "# ! pip install imbalanced-ensemble           \n",
    "# ! pip install threadpoolctl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48f205d1-e543-4532-a098-2be27173f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Mimimkh/SMOTE-ENC-code/\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.utils import check_array, _safe_indexing, sparsefuncs_fast, check_X_y, check_random_state\n",
    "from numbers import Integral\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "\n",
    "class mSMOTENC():\n",
    "    \n",
    "    def __init__(self, categorical_features):\n",
    "        self.categorical_features = categorical_features\n",
    "        \n",
    "    def chk_neighbors(self, nn_object, additional_neighbor):\n",
    "        if isinstance(nn_object, Integral):\n",
    "            return NearestNeighbors(n_neighbors=nn_object + additional_neighbor)\n",
    "        elif isinstance(nn_object, KNeighborsMixin):\n",
    "            return clone(nn_object)\n",
    "        else:\n",
    "            raise_isinstance_error(nn_name, [int, KNeighborsMixin], nn_object)     \n",
    "    \n",
    "    def generate_samples(self, X, nn_data, nn_num, rows, cols, steps, continuous_features_,):\n",
    "        rng = check_random_state(42)\n",
    "\n",
    "        diffs = nn_data[nn_num[rows, cols]] - X[rows]\n",
    "\n",
    "        if sparse.issparse(X):\n",
    "            sparse_func = type(X).__name__\n",
    "            steps = getattr(sparse, sparse_func)(steps)\n",
    "            X_new = X[rows] + steps.multiply(diffs)\n",
    "        else:\n",
    "            X_new = X[rows] + steps * diffs \n",
    "\n",
    "        X_new = (X_new.tolil() if sparse.issparse(X_new) else X_new)\n",
    "        # convert to dense array since scipy.sparse doesn't handle 3D\n",
    "        nn_data = (nn_data.toarray() if sparse.issparse(nn_data) else nn_data)\n",
    "        all_neighbors = nn_data[nn_num[rows]]\n",
    "\n",
    "        for idx in range(continuous_features_.size, X.shape[1]):\n",
    "            mode = stats.mode(all_neighbors[:, :, idx], axis = 1)[0]\n",
    "            X_new[:, idx] = np.ravel(mode)\n",
    "\n",
    "        return X_new\n",
    "    \n",
    "    def make_samples(self, X, y_dtype, y_type, nn_data, nn_num, n_samples, continuous_features_, step_size=1.0):\n",
    "        random_state = check_random_state(42)\n",
    "        samples_indices = random_state.randint(low=0, high=len(nn_num.flatten()), size=n_samples)    \n",
    "        steps = step_size * random_state.uniform(size=n_samples)[:, np.newaxis]\n",
    "        rows = np.floor_divide(samples_indices, nn_num.shape[1])\n",
    "        cols = np.mod(samples_indices, nn_num.shape[1])\n",
    "\n",
    "        X_new = self.generate_samples(X, nn_data, nn_num, rows, cols, steps, continuous_features_)\n",
    "        y_new = np.full(n_samples, fill_value=y_type, dtype=y_dtype)\n",
    "        \n",
    "        return X_new, y_new\n",
    "    \n",
    "    def cat_corr_pandas(self, X, target_df, target_column, target_value):\n",
    "    # X has categorical columns\n",
    "        categorical_columns = list(X.columns)\n",
    "        X = pd.concat([X, target_df], axis=1)\n",
    "\n",
    "        # filter X for target value\n",
    "        is_target = X.loc[:, target_column] == target_value\n",
    "        X_filtered = X.loc[is_target, :]\n",
    "\n",
    "        X_filtered.drop(target_column, axis=1, inplace=True)\n",
    "\n",
    "        # get columns in X\n",
    "        nrows = len(X)\n",
    "        encoded_dict_list = []\n",
    "        nan_dict = dict({})\n",
    "        c = 0\n",
    "        imb_ratio = len(X_filtered)/len(X)\n",
    "        OE_dict = {}\n",
    "        \n",
    "        for column in categorical_columns:\n",
    "            for level in list(X.loc[:, column].unique()):\n",
    "                \n",
    "                # filter rows where level is present\n",
    "                row_level_filter = X.loc[:, column] == level\n",
    "                rows_in_level = len(X.loc[row_level_filter, :])\n",
    "                \n",
    "                # number of rows in level where target is 1\n",
    "                O = len(X.loc[is_target & row_level_filter, :])\n",
    "                E = rows_in_level * imb_ratio\n",
    "                # Encoded value = chi, i.e. (observed - expected)/expected\n",
    "                ENC = (O - E) / E\n",
    "                OE_dict[level] = ENC\n",
    "                \n",
    "            encoded_dict_list.append(OE_dict)\n",
    "\n",
    "            X.loc[:, column] = X[column].map(OE_dict)\n",
    "            # print(f'X.loc[:, {column}]', X.loc[:, column])\n",
    "            # nan_idx_array = np.ravel(np.argwhere(np.isnan(X.loc[:, column])))\n",
    "            nan_idx_array = np.array([0])\n",
    "            if len(nan_idx_array) > 0 :\n",
    "                nan_dict[c] = nan_idx_array\n",
    "            c = c + 1\n",
    "            X.loc[:, column].fillna(-1, inplace = True)\n",
    "                \n",
    "        X.drop(target_column, axis=1, inplace=True)\n",
    "        return X, encoded_dict_list, nan_dict\n",
    "\n",
    "    def fit_resample(self, X, y):\n",
    "\n",
    "        X_cat_encoded, encoded_dict_list, nan_dict = self.cat_corr_pandas(X.iloc[:,np.asarray(self.categorical_features)],  y, target_column='fake_cat1', target_value=1)\n",
    "\n",
    "        X_cat_encoded = np.array(X_cat_encoded)\n",
    "        y = np.ravel(y)\n",
    "        X = np.array(X)\n",
    "\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        target_stats = dict(zip(unique, counts))\n",
    "        n_sample_majority = max(target_stats.values())\n",
    "        class_majority = max(target_stats, key=target_stats.get)\n",
    "        sampling_strategy = {key: n_sample_majority - value for (key, value) in target_stats.items() if key != class_majority}\n",
    "\n",
    "        n_features_ = X.shape[1]\n",
    "        categorical_features = np.asarray(self.categorical_features)\n",
    "        if categorical_features.dtype.name == 'bool':\n",
    "            categorical_features_ = np.flatnonzero(categorical_features)\n",
    "        else:\n",
    "            if any([cat not in np.arange(n_features_) for cat in categorical_features]):\n",
    "                raise ValueError('Some of the categorical indices are out of range. Indices'\n",
    "                            ' should be between 0 and {}'.format(n_features_))\n",
    "            categorical_features_ = categorical_features\n",
    "\n",
    "        continuous_features_ = np.setdiff1d(np.arange(n_features_),categorical_features_)\n",
    "\n",
    "        target_stats = Counter(y)\n",
    "        class_minority = min(target_stats, key=target_stats.get)\n",
    "\n",
    "        X_continuous = X[:, continuous_features_]\n",
    "        X_continuous = check_array(X_continuous, accept_sparse=['csr', 'csc'])\n",
    "        X_minority = _safe_indexing(X_continuous, np.flatnonzero(y == class_minority))\n",
    "\n",
    "        if sparse.issparse(X):\n",
    "            if X.format == 'csr':\n",
    "                _, var = sparsefuncs_fast.csr_mean_variance_axis0(X_minority)\n",
    "            else:\n",
    "                _, var = sparsefuncs_fast.csc_mean_variance_axis0(X_minority)\n",
    "        else:\n",
    "            var = X_minority.var(axis=0)\n",
    "        median_std_ = np.median(np.sqrt(var))\n",
    "\n",
    "        X_categorical = X[:, categorical_features_]\n",
    "        X_copy = np.hstack((X_continuous, X_categorical))\n",
    "        \n",
    "        X_cat_encoded = X_cat_encoded * median_std_\n",
    "        X_encoded = np.hstack((X_continuous, X_cat_encoded))\n",
    "        X_resampled = X_encoded.copy()\n",
    "        y_resampled = y.copy()\n",
    "\n",
    "\n",
    "        for class_sample, n_samples in sampling_strategy.items():\n",
    "            if n_samples == 0:\n",
    "                continue\n",
    "            target_class_indices = np.flatnonzero(y == class_sample)\n",
    "            X_class = _safe_indexing(X_encoded, target_class_indices)\n",
    "            nn_k_ = self.chk_neighbors(5, 1)\n",
    "            nn_k_.fit(X_class)\n",
    "            nns = nn_k_.kneighbors(X_class, return_distance=False)[:, 1:]\n",
    "\n",
    "            X_new, y_new = self.make_samples(X_class, y.dtype, class_sample, X_class, nns, n_samples, continuous_features_, 1.0)\n",
    "            if sparse.issparse(X_new):\n",
    "                X_resampled = sparse.vstack([X_resampled, X_new])\n",
    "                sparse_func = 'tocsc' if X.format == 'csc' else 'tocsr'\n",
    "                X_resampled = getattr(X_resampled, sparse_func)()\n",
    "            else:\n",
    "                X_resampled = np.vstack((X_resampled, X_new))\n",
    "            y_resampled = np.hstack((y_resampled, y_new))\n",
    "\n",
    "        X_resampled_copy = X_resampled.copy()\n",
    "        i = 0\n",
    "        for col in range(continuous_features_.size, X.shape[1]):\n",
    "            encoded_dict = encoded_dict_list[i]\n",
    "            i = i + 1\n",
    "            for key, value in encoded_dict.items():\n",
    "                X_resampled_copy[:, col] = np.where(np.round(X_resampled_copy[:, col], 4) == np.round(value * median_std_, 4), key, X_resampled_copy[:, col])\n",
    "\n",
    "        for key, value in nan_dict.items():\n",
    "            for item in value:\n",
    "                X_resampled_copy[item, continuous_features_.size + key] = X_copy[item, continuous_features_.size + key]\n",
    "\n",
    "               \n",
    "        X_resampled = X_resampled_copy   \n",
    "        indices_reordered = np.argsort(np.hstack((continuous_features_, categorical_features_)))\n",
    "        if sparse.issparse(X_resampled):\n",
    "            col_indices = X_resampled.indices.copy()\n",
    "            for idx, col_idx in enumerate(indices_reordered):\n",
    "                mask = X_resampled.indices == col_idx\n",
    "                col_indices[mask] = idx\n",
    "            X_resampled.indices = col_indices\n",
    "        else:\n",
    "            X_resampled = X_resampled[:, indices_reordered]\n",
    "        return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "384b570b-8838-4324-9b8f-2a8b9774b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/yeast4-5-fold/yeast4-5-1tra.xlsx\n",
      "<class 'pandas.core.frame.DataFrame'> 8        Gvh   Alm   Mit  Erl  Pox   Vac   Nuc  fake_cat1\n",
      "0     0.61  0.47  0.13  0.5  0.0  0.48  0.22          1\n",
      "1     0.67  0.48  0.27  0.5  0.0  0.53  0.22          1\n",
      "2     0.62  0.49  0.15  0.5  0.0  0.53  0.22          1\n",
      "3     0.44  0.48  0.54  0.5  0.0  0.48  0.22          1\n",
      "4     0.54  0.48  0.65  0.5  0.0  0.53  0.22          1\n",
      "...    ...   ...   ...  ...  ...   ...   ...        ...\n",
      "1182  0.40  0.66  0.35  0.5  0.0  0.43  0.11          1\n",
      "1183  0.62  0.43  0.17  0.5  0.0  0.53  0.22          1\n",
      "1184  0.43  0.61  0.40  0.5  0.0  0.48  0.47          1\n",
      "1185  0.40  0.60  0.16  0.5  0.0  0.53  0.39          1\n",
      "1186  0.54  0.54  0.13  0.5  0.0  0.53  0.22          1\n",
      "\n",
      "[1187 rows x 8 columns]\n",
      "(2294, 8) [array([0.13, 0.14, 0.16, ..., 0.9 , 0.92, 0.94]), array([0.21, 0.22, 0.24, ..., 0.75, 0.79, 1.  ]), array([0.        , 0.04      , 0.04309743, ..., 0.86      , 0.87      ,\n",
      "       1.        ]), array([0.5       , 0.506166  , 0.51206312, 0.51606998, 0.51946484,\n",
      "       0.5217493 , 0.53737584, 0.56833318, 0.56897867, 0.63420524,\n",
      "       0.64581851, 0.65526752, 0.65593265, 0.66740139, 0.68073703,\n",
      "       0.69687353, 0.70382484, 0.70669577, 0.7099569 , 0.71649187,\n",
      "       0.72397641, 0.73679867, 0.75557671, 0.77238993, 0.80191365,\n",
      "       0.81334534, 0.81365574, 0.8199318 , 0.82695014, 0.83783312,\n",
      "       0.8700934 , 0.87012311, 0.87028828, 0.87679898, 0.88809119,\n",
      "       0.89397758, 0.93766866, 0.95166178, 0.95994258, 1.        ]), array([0.  , 0.5 , 0.83]), array([0.  , 0.13, 0.19, ..., 0.63, 0.69, 0.72]), array([0.        , 0.01      , 0.11      , 0.14      , 0.16      ,\n",
      "       0.18      , 0.19      , 0.21      , 0.22      , 0.22008626,\n",
      "       0.22029329, 0.22060503, 0.22062736, 0.22063808, 0.22109649,\n",
      "       0.22115154, 0.22124783, 0.22128179, 0.22137226, 0.2215044 ,\n",
      "       0.22165804, 0.22185366, 0.22192627, 0.22196692, 0.22205137,\n",
      "       0.22244008, 0.22248977, 0.22254453, 0.22273423, 0.22275289,\n",
      "       0.22286049, 0.22311341, 0.22313704, 0.22313932, 0.22347119,\n",
      "       0.22364453, 0.22414643, 0.2242443 , 0.22434125, 0.22462244,\n",
      "       0.22466929, 0.22474913, 0.22480416, 0.22481882, 0.22485654,\n",
      "       0.22505362, 0.22527167, 0.22538845, 0.22539049, 0.22539577,\n",
      "       0.22546354, 0.22548107, 0.22585496, 0.22595789, 0.22602834,\n",
      "       0.22606932, 0.22614953, 0.22656991, 0.22660464, 0.22662389,\n",
      "       0.22675627, 0.22684467, 0.22695841, 0.22701142, 0.22709183,\n",
      "       0.22710612, 0.22732154, 0.22732396, 0.22751045, 0.22777319,\n",
      "       0.22787165, 0.22795148, 0.22803799, 0.2280698 , 0.22818707,\n",
      "       0.22824227, 0.22827234, 0.22839058, 0.22839266, 0.22860807,\n",
      "       0.22879443, 0.22885054, 0.22915911, 0.22918953, 0.22920834,\n",
      "       0.2292317 , 0.22930931, 0.22980826, 0.23      , 0.23002732,\n",
      "       0.23004895, 0.23014482, 0.23019457, 0.23023344, 0.23025252,\n",
      "       0.23029874, 0.23037805, 0.23039431, 0.23045099, 0.23046301,\n",
      "       0.23050376, 0.23054868, 0.23061726, 0.23069267, 0.23069806,\n",
      "       0.23100745, 0.23115761, 0.23118066, 0.23149773, 0.23170933,\n",
      "       0.23176285, 0.2317679 , 0.23185558, 0.23190544, 0.23195346,\n",
      "       0.23202554, 0.23217411, 0.23220196, 0.2322536 , 0.23250875,\n",
      "       0.23263229, 0.23263974, 0.23289901, 0.23368186, 0.233762  ,\n",
      "       0.23391459, 0.23393561, 0.23443247, 0.2346654 , 0.23467204,\n",
      "       0.23473759, 0.23532292, 0.23554183, 0.23577357, 0.23593009,\n",
      "       0.23595306, 0.23595447, 0.23596011, 0.23602047, 0.23618474,\n",
      "       0.23636989, 0.23645839, 0.23654196, 0.23687191, 0.23696523,\n",
      "       0.23697196, 0.23716793, 0.23747258, 0.23762291, 0.23780002,\n",
      "       0.23804835, 0.23827282, 0.23829133, 0.23840058, 0.2384095 ,\n",
      "       0.23847032, 0.2385813 , 0.23901719, 0.23910009, 0.23915693,\n",
      "       0.2391736 , 0.23917942, 0.2393431 , 0.23969322, 0.23989313,\n",
      "       0.24      , 0.2400278 , 0.24008461, 0.24014392, 0.24028118,\n",
      "       0.24068669, 0.2407621 , 0.24077878, 0.24080498, 0.24086855,\n",
      "       0.24088062, 0.24088834, 0.2409999 , 0.24116603, 0.24125089,\n",
      "       0.24130966, 0.24137872, 0.24166758, 0.24177161, 0.24193077,\n",
      "       0.24198915, 0.24205289, 0.24210621, 0.24213208, 0.24245389,\n",
      "       0.2425533 , 0.24283669, 0.24291638, 0.24296305, 0.24307991,\n",
      "       0.24391978, 0.24397199, 0.24447296, 0.24458274, 0.24474043,\n",
      "       0.24479218, 0.24486746, 0.24509032, 0.24510832, 0.24529443,\n",
      "       0.24534279, 0.2454162 , 0.24560537, 0.24586128, 0.24590001,\n",
      "       0.24648075, 0.24649102, 0.24654298, 0.24655218, 0.24657933,\n",
      "       0.24695738, 0.24706054, 0.2473904 , 0.24743951, 0.24744683,\n",
      "       0.24767064, 0.24770768, 0.24774986, 0.24808637, 0.24809028,\n",
      "       0.24811685, 0.24817617, 0.24820202, 0.24824206, 0.24826377,\n",
      "       0.24850342, 0.24859102, 0.2495989 , 0.24974033, 0.24977451,\n",
      "       0.25      , 0.2501879 , 0.25027311, 0.25033053, 0.25068172,\n",
      "       0.25072198, 0.2510211 , 0.25102822, 0.2510627 , 0.2511828 ,\n",
      "       0.25131102, 0.25131245, 0.25160741, 0.25164266, 0.25175852,\n",
      "       0.25180755, 0.25218896, 0.25222256, 0.25229841, 0.25233123,\n",
      "       0.25234968, 0.25244189, 0.2527152 , 0.25276409, 0.25287757,\n",
      "       0.25298127, 0.25379133, 0.25391036, 0.25391901, 0.25400878,\n",
      "       0.25418072, 0.25427826, 0.2545773 , 0.25486423, 0.25512222,\n",
      "       0.25572492, 0.25580172, 0.25595422, 0.25628414, 0.25635698,\n",
      "       0.25692246, 0.25716942, 0.25728652, 0.25753362, 0.25798693,\n",
      "       0.25841367, 0.25844693, 0.25845631, 0.25851969, 0.25867366,\n",
      "       0.25868623, 0.2589788 , 0.25903461, 0.25905264, 0.25914571,\n",
      "       0.25950472, 0.25959315, 0.25967006, 0.25997934, 0.26      ,\n",
      "       0.26003126, 0.26003518, 0.2604886 , 0.26050039, 0.26059742,\n",
      "       0.26065909, 0.26113072, 0.26125435, 0.26146456, 0.26154617,\n",
      "       0.26182381, 0.26216131, 0.26221309, 0.26354709, 0.26357223,\n",
      "       0.2636062 , 0.26373689, 0.26377032, 0.26393285, 0.26400949,\n",
      "       0.26418929, 0.26436799, 0.26457276, 0.26462267, 0.26472025,\n",
      "       0.26477123, 0.26559117, 0.26571494, 0.26583658, 0.26590588,\n",
      "       0.26619346, 0.26646749, 0.26646899, 0.2668055 , 0.26720297,\n",
      "       0.26721845, 0.26739262, 0.26743607, 0.26746511, 0.26754318,\n",
      "       0.26769346, 0.26782182, 0.26792699, 0.26793386, 0.26793579,\n",
      "       0.26803282, 0.26813442, 0.2681465 , 0.26821702, 0.26824614,\n",
      "       0.26868209, 0.26882411, 0.26906165, 0.26915133, 0.26928098,\n",
      "       0.26976943, 0.26981957, 0.2698422 , 0.26985736, 0.27      ,\n",
      "       0.27029056, 0.27033135, 0.27039638, 0.27067235, 0.27099708,\n",
      "       0.2710575 , 0.27112209, 0.27127182, 0.27135488, 0.2715596 ,\n",
      "       0.27159321, 0.27163091, 0.27185308, 0.27254217, 0.27262762,\n",
      "       0.27278746, 0.27334914, 0.27347944, 0.27358277, 0.27425713,\n",
      "       0.27430777, 0.27431512, 0.27437607, 0.27493004, 0.27565319,\n",
      "       0.27567494, 0.27575858, 0.27579772, 0.27731188, 0.27734813,\n",
      "       0.27762617, 0.2777586 , 0.27845204, 0.27856116, 0.27869586,\n",
      "       0.27889715, 0.27891519, 0.27896391, 0.27921664, 0.27923151,\n",
      "       0.27926713, 0.27964836, 0.28      , 0.28010286, 0.28056702,\n",
      "       0.28114981, 0.28204475, 0.28224223, 0.28246636, 0.28292917,\n",
      "       0.28320243, 0.28323859, 0.28334782, 0.28339853, 0.28342103,\n",
      "       0.28364793, 0.28366429, 0.28376061, 0.28386981, 0.28458763,\n",
      "       0.28536728, 0.28542674, 0.28579183, 0.28579845, 0.28655886,\n",
      "       0.28676799, 0.28791858, 0.28819359, 0.28829799, 0.28849251,\n",
      "       0.2886211 , 0.28882779, 0.28886923, 0.28896116, 0.28900049,\n",
      "       0.28914866, 0.28929761, 0.28936252, 0.2896075 , 0.29      ,\n",
      "       0.29002972, 0.29041469, 0.29104643, 0.29147214, 0.29281078,\n",
      "       0.29298907, 0.29313116, 0.29325721, 0.29336144, 0.29338509,\n",
      "       0.29371372, 0.29383288, 0.29456225, 0.29472179, 0.29472378,\n",
      "       0.29543996, 0.29586314, 0.29670405, 0.2971754 , 0.29742049,\n",
      "       0.29764498, 0.2981251 , 0.2981328 , 0.29822137, 0.29824049,\n",
      "       0.29840171, 0.29854139, 0.29872668, 0.29947918, 0.3       ,\n",
      "       0.30091632, 0.30092823, 0.30174497, 0.3027169 , 0.30294452,\n",
      "       0.30323808, 0.30572457, 0.30665081, 0.3068468 , 0.30685107,\n",
      "       0.30730238, 0.30822605, 0.30925978, 0.30928732, 0.31      ,\n",
      "       0.3101762 , 0.31042375, 0.31085027, 0.31105809, 0.31146257,\n",
      "       0.31154883, 0.3116507 , 0.3118603 , 0.31189538, 0.31196092,\n",
      "       0.31205806, 0.31308335, 0.31366057, 0.31399483, 0.31436159,\n",
      "       0.31493255, 0.3155181 , 0.31554396, 0.31774982, 0.31836789,\n",
      "       0.31843582, 0.32      , 0.32000964, 0.32053467, 0.32162699,\n",
      "       0.32203144, 0.3224788 , 0.32303893, 0.32335049, 0.32338475,\n",
      "       0.32405948, 0.32691718, 0.32727098, 0.3296546 , 0.33      ,\n",
      "       0.33107006, 0.332734  , 0.33306605, 0.33596009, 0.33997376,\n",
      "       0.34      , 0.34248045, 0.34278482, 0.34328453, 0.34331013,\n",
      "       0.34500457, 0.34588095, 0.34619391, 0.34855291, 0.34881461,\n",
      "       0.35      , 0.35147821, 0.35515333, 0.35948891, 0.36      ,\n",
      "       0.36181892, 0.36632375, 0.37      , 0.3761229 , 0.38      ,\n",
      "       0.38102485, 0.38548953, 0.38674848, 0.38812469, 0.38814423,\n",
      "       0.39      , 0.4       , 0.41      , 0.42      , 0.43      ,\n",
      "       0.44      , 0.45      , 0.46      , 0.47      , 0.48      ,\n",
      "       0.49      , 0.5       , 0.51      , 0.52      , 0.54      ,\n",
      "       0.55      , 0.56      , 0.57      , 0.58      , 0.59      ,\n",
      "       0.6       , 0.61      , 0.62      , 0.63      , 0.64      ,\n",
      "       0.65      , 0.66      , 0.67      , 0.68      , 0.69      ,\n",
      "       0.7       , 0.71      , 0.72      , 0.73      , 0.75      ,\n",
      "       0.79      , 0.8       , 0.83      , 0.99      , 1.        ]), array([-0.07552773,  0.07552773,  1.        ])]\n"
     ]
    }
   ],
   "source": [
    "# from SMOTE_ENC import mSMOTENC\n",
    "\n",
    "dataset = 'yeast4-5-fold'\n",
    "\n",
    "mcc = []\n",
    "f1 = []\n",
    "auc_a = []\n",
    "gmean = []\n",
    "times = []\n",
    "y_preds = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "traFiles = sorted(glob.glob(base_path+dataset+'/*tra.xlsx'))\n",
    "tstFiles = sorted(glob.glob(base_path+dataset+'/*tst.xlsx'))\n",
    "for traPath, tstPath in zip(traFiles, tstFiles):\n",
    "    print(traPath)\n",
    "\n",
    "    df_train = pd.read_excel(traPath)\n",
    "    df_test = pd.read_excel(tstPath)\n",
    "\n",
    "    x_train= df_train.iloc[:, 1:-1]\n",
    "    y_train = df_train.iloc[:, -1]\n",
    "    x_test= df_test.iloc[:, 1:-1]\n",
    "    y_test = df_test.iloc[:, -1]\n",
    "\n",
    "    #####\n",
    "    # for some dataset get error Unknown label type: 'unknown'\n",
    "    y_train = y_train.astype('int')\n",
    "    y_test = y_test.astype('int')\n",
    "\n",
    "    x_train['fake_cat1'] = 1\n",
    "    print(type(x_train), x_train.shape[1], x_train)\n",
    "    \n",
    "    st = time.time()\n",
    "    \n",
    "    msmotenc = mSMOTENC(categorical_features=[x_train.shape[1]-1])\n",
    "    X_resampled, y_resampled = msmotenc.fit_resample(x_train, y_train)\n",
    "    print(X_resampled.shape, [np.unique(X_resampled[:,i]) for i in range(x_train.shape[1]) ])\n",
    "    break\n",
    "    \n",
    "    \n",
    "#     clf = classifiers[classifier]\n",
    "        \n",
    "#     clf.fit(x_train, y_train)\n",
    "\n",
    "#     y_pred = clf.predict(x_test) \n",
    "#     et = time.time()\n",
    "#     y_preds.append(y_pred)\n",
    "#     # compute error\n",
    "#     mcc.append(matthews_corrcoef(y_test, y_pred))\n",
    "#     #--------------------------------\n",
    "#     fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "#     auc_a.append(auc(fpr, tpr))\n",
    "#     #--------------------------------\n",
    "#     f1.append(f1_score(y_test, y_pred))\n",
    "#     #--------------------------------\n",
    "#     gmean.append(geometric_mean_score(y_test, y_pred, labels=[1, -1]))\n",
    "\n",
    "#     #time of train and test\n",
    "#     times.append(et - st)\n",
    "\n",
    "#     precisions.append(precision_score(y_test, y_pred))\n",
    "#     recalls.append(precision_score(y_test, y_pred))\n",
    "\n",
    "#     {\"precision\": precisions, \"recall\": recalls, \"mcc\": mcc, \"auc\": auc_a, \"f1\": f1, \"gmean\": gmean, \"exe_time\": times, \"y_pred\": y_pred}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4737c5-11b3-4729-95c5-fd7458fe1d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97ceea7-d25a-4b9f-9da9-66198967610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_dot_dat_file(path):\n",
    "    datContent = [i.strip().split() for i in open(path).readlines()]\n",
    "    r = re.compile(\"@inputs.*\")\n",
    "    _at_data = datContent.index(['@data'])\n",
    "    assert datContent[0][0] == '@relation'\n",
    "    assert datContent[_at_data-1][0] == '@outputs'\n",
    "    assert datContent[_at_data-2][0] == '@inputs'\n",
    "    print(datContent[_at_data-3][2:])\n",
    "    assert len(datContent[_at_data-3][2:]) == 2   # Two Class\n",
    "\n",
    "    col_names = datContent[_at_data-2][1:]\n",
    "    col_names.append(datContent[_at_data-1][1])\n",
    "    \n",
    "    df = pd.read_csv(path, skiprows=_at_data+1, names=col_names, sep=r', ', engine='python')\n",
    "    # df = pd.read_csv(path, skiprows=_at_data+1, names=col_names, sep=\", \", engine='python')\n",
    "\n",
    "    class1 = datContent[_at_data-3][2:][0].replace(\"{\",\"\").replace(\",\",\"\")\n",
    "    class2 = datContent[_at_data-3][2:][1].replace(\"}\",\"\").replace(\",\",\"\")\n",
    "\n",
    "    df['Class'] = df['Class'].replace({class1: 1, class2: -1})\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780530b-2810-424b-8feb-0a847faf8ca1",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af89ab8a-ec78-4dbd-a01e-3d02ce85b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# base_path = 'Datasets/'\n",
    "# # need_to_convert = ['wisconsin-5-fold','new-thyroid2-5-fold','new-thyroid1-5-fold']\n",
    "# # need_to_convert = ['yeast-1_vs_7-5-fold', 'led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold', 'ecoli-0-3-4-6_vs_5-5-fold', 'abalone19-5-', 'abalone19-5-fold']\n",
    "# # need_to_convert = ['ecoli-0-1_vs_5-5-fold','ecoli-0-1-4-7_vs_5-6-5-fold','ecoli-0-3-4-7_vs_5-6-5-fold','glass-0-1-4-6_vs_2-5-fold', 'ecoli-0-4-6_vs_5-5-fold',\n",
    "# #                   'yeast-0-3-5-9_vs_7-8-5-fold','yeast-1-2-8-9_vs_7-5-fold']\n",
    "# need_to_convert = ['yeast-1-2-8-9_vs_7-5-fold']\n",
    "# for needed in need_to_convert:\n",
    "#     for datFile in glob.glob(base_path+needed+'/*.dat'):\n",
    "#         print(datFile)\n",
    "#         df = read_dot_dat_file(datFile)\n",
    "#         df.to_excel(base_path+needed+'/'+datFile.split('/')[-1].split('.')[0]+'.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b312338-1179-4c80-bf40-7a14b9d12047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import random  \n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc,f1_score, matthews_corrcoef, precision_score, recall_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imbalanced_ensemble.ensemble import SMOTEBoostClassifier\n",
    "from maatpy.classifiers import AdaCost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c891321f-9db4-46cb-87e0-3d1689692e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Apply the random-forest classifier along with the NEW SMOTE method\n",
    "# from sklearn.model_selection import GridSearchCV \n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from imblearn.pipeline import Pipeline, make_pipeline\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # samp_pipeline = make_pipeline(mSMOTENC(categorical_features = []), \n",
    "# #                               DecisionTreeClassifier(max_depth=10))\n",
    "# # # check model performance on different values of hyper-parameters.\n",
    "# # grid_search = GridSearchCV(samp_pipeline, param_grid=param_grid, cv=kfold, scoring='balanced_accuracy',\n",
    "# #                         return_train_score=True, n_jobs = -1, verbose = 2)\n",
    "# # grid_search.fit(X_train, y_train)\n",
    "# # best_grid = grid_search.best_estimator_\n",
    "# # best_grid\n",
    "\n",
    "# mSMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f6a92d6-54cc-46a5-929a-3918bc55dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = 'Datasets/'\n",
    "datasets  = os.listdir(base_path) \n",
    "classifiers = {\"RUS\": RUSBoostClassifier(random_state=0, algorithm='SAMME', base_estimator=DecisionTreeClassifier(max_depth=10)),\n",
    "              \"SMOTE\": SMOTEBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10), n_estimators = 100, algorithm='SAMME', random_state=0),\n",
    "              \"Ada1\": AdaCost(base_estimator=DecisionTreeClassifier(max_depth=10), n_estimators=100, algorithm='adac1',random_state=0),\n",
    "              \"AdaCost\": AdaCost(base_estimator=DecisionTreeClassifier(max_depth=10), n_estimators=100, algorithm='adacost',random_state=0)}\n",
    "            \n",
    "\n",
    "def clasify(dataset, classifier):\n",
    "    mcc = []\n",
    "    f1 = []\n",
    "    auc_a = []\n",
    "    gmean = []\n",
    "    times = []\n",
    "    y_preds = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    traFiles = sorted(glob.glob(base_path+dataset+'/*tra.xlsx'))\n",
    "    tstFiles = sorted(glob.glob(base_path+dataset+'/*tst.xlsx'))\n",
    "    for traPath, tstPath in zip(traFiles, tstFiles):\n",
    "        print(traPath)\n",
    "        \n",
    "        df_train = pd.read_excel(traPath)\n",
    "        df_test = pd.read_excel(tstPath)\n",
    "\n",
    "        x_train= df_train.iloc[:, 1:-1]\n",
    "        y_train = df_train.iloc[:, -1]\n",
    "        x_test= df_test.iloc[:, 1:-1]\n",
    "        y_test = df_test.iloc[:, -1]\n",
    "        \n",
    "        #####\n",
    "        # for some dataset get error Unknown label type: 'unknown'\n",
    "        y_train = y_train.astype('int')\n",
    "        y_test = y_test.astype('int')\n",
    "        \n",
    "        st = time.time()\n",
    "        clf = classifiers[classifier]\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(x_test) \n",
    "        et = time.time()\n",
    "        y_preds.append(y_pred)\n",
    "        # compute error\n",
    "        mcc.append(matthews_corrcoef(y_test, y_pred))\n",
    "        #--------------------------------\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "        auc_a.append(auc(fpr, tpr))\n",
    "        #--------------------------------\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        #--------------------------------\n",
    "        gmean.append(geometric_mean_score(y_test, y_pred, labels=[1, -1]))\n",
    "        \n",
    "        #time of train and test\n",
    "        times.append(et - st)\n",
    "        \n",
    "        precisions.append(precision_score(y_test, y_pred))\n",
    "        recalls.append(precision_score(y_test, y_pred))\n",
    "        \n",
    "    return {\"precision\": precisions, \"recall\": recalls, \"mcc\": mcc, \"auc\": auc_a, \"f1\": f1, \"gmean\": gmean, \"exe_time\": times, \"y_pred\": y_pred}\n",
    "\n",
    "# aaaaaa =  clasify(datasets[0], 'Ada1')\n",
    "# aaaaaa =  clasify('yeast-1-2-8-9_vs_7-5-fold', 'RUS')\n",
    "# aaaaaa\n",
    "# clasify('yeast4-5-fold', 'OUBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87880c2f-2c62-4c5a-805d-03b2595365ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/yeast4-5-fold/yeast4-5-1tra.xlsx\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'check_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     st \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     30\u001b[0m     msmotenc \u001b[38;5;241m=\u001b[39m mSMOTENC([])\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmsmotenc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#     clf = classifiers[classifier]\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#     clf.fit(x_train, y_train)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#     {\"precision\": precisions, \"recall\": recalls, \"mcc\": mcc, \"auc\": auc_a, \"f1\": f1, \"gmean\": gmean, \"exe_time\": times, \"y_pred\": y_pred}\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 129\u001b[0m, in \u001b[0;36mmSMOTENC.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    126\u001b[0m class_minority \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(target_stats, key\u001b[38;5;241m=\u001b[39mtarget_stats\u001b[38;5;241m.\u001b[39mget)\n\u001b[1;32m    128\u001b[0m X_continuous \u001b[38;5;241m=\u001b[39m X[:, continuous_features_]\n\u001b[0;32m--> 129\u001b[0m X_continuous \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m(X_continuous, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    130\u001b[0m X_minority \u001b[38;5;241m=\u001b[39m safe_indexing(X_continuous, np\u001b[38;5;241m.\u001b[39mflatnonzero(y \u001b[38;5;241m==\u001b[39m class_minority))\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'check_array' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = 'yeast4-5-fold'\n",
    "\n",
    "mcc = []\n",
    "f1 = []\n",
    "auc_a = []\n",
    "gmean = []\n",
    "times = []\n",
    "y_preds = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "traFiles = sorted(glob.glob(base_path+dataset+'/*tra.xlsx'))\n",
    "tstFiles = sorted(glob.glob(base_path+dataset+'/*tst.xlsx'))\n",
    "for traPath, tstPath in zip(traFiles, tstFiles):\n",
    "    print(traPath)\n",
    "\n",
    "    df_train = pd.read_excel(traPath)\n",
    "    df_test = pd.read_excel(tstPath)\n",
    "\n",
    "    x_train= df_train.iloc[:, 1:-1]\n",
    "    y_train = df_train.iloc[:, -1]\n",
    "    x_test= df_test.iloc[:, 1:-1]\n",
    "    y_test = df_test.iloc[:, -1]\n",
    "\n",
    "    #####\n",
    "    # for some dataset get error Unknown label type: 'unknown'\n",
    "    y_train = y_train.astype('int')\n",
    "    y_test = y_test.astype('int')\n",
    "\n",
    "    st = time.time()\n",
    "    msmotenc = mSMOTENC([])\n",
    "    print(msmotenc.fit_resample(x_train, y_train))\n",
    "    break\n",
    "    \n",
    "    \n",
    "#     clf = classifiers[classifier]\n",
    "        \n",
    "#     clf.fit(x_train, y_train)\n",
    "\n",
    "#     y_pred = clf.predict(x_test) \n",
    "#     et = time.time()\n",
    "#     y_preds.append(y_pred)\n",
    "#     # compute error\n",
    "#     mcc.append(matthews_corrcoef(y_test, y_pred))\n",
    "#     #--------------------------------\n",
    "#     fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "#     auc_a.append(auc(fpr, tpr))\n",
    "#     #--------------------------------\n",
    "#     f1.append(f1_score(y_test, y_pred))\n",
    "#     #--------------------------------\n",
    "#     gmean.append(geometric_mean_score(y_test, y_pred, labels=[1, -1]))\n",
    "\n",
    "#     #time of train and test\n",
    "#     times.append(et - st)\n",
    "\n",
    "#     precisions.append(precision_score(y_test, y_pred))\n",
    "#     recalls.append(precision_score(y_test, y_pred))\n",
    "\n",
    "#     {\"precision\": precisions, \"recall\": recalls, \"mcc\": mcc, \"auc\": auc_a, \"f1\": f1, \"gmean\": gmean, \"exe_time\": times, \"y_pred\": y_pred}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f0a8692-aeb2-4fcd-a2d8-bc54829958fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #temp \n",
    "# for i in range(len(datasets)):\n",
    "#     if not os.path.isdir('./Results/'+datasets[i]):\n",
    "#         os.mkdir('./Results/'+datasets[i])\n",
    "#     for classifier in classifiers:\n",
    "#         if not os.path.isdir('./Results/'+datasets[i]+'/'+classifier):\n",
    "#             os.mkdir('./Results/'+datasets[i]+'/'+classifier)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e88568-2e7f-473c-b2a4-e2737994cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_files(dataset, classifier, dict_res):\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/mcc.npy',dict_res['mcc'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/auc.npy',dict_res['auc'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/f1.npy',dict_res['f1'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/gmean.npy',dict_res['gmean'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/exe_time.npy',dict_res['exe_time'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/y_pred.npy',dict_res['y_pred'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f9ec686-ac23-4236-ba0e-47c56c1cb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be00f465-4b1a-42e6-a951-9c7dc485764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for classifier in classifiers:\n",
    "# #     for dataset in datasets:\n",
    "# #         if not os.path.exists('./Results/'+dataset+'/'+classifier+'/y_pred.npy'):\n",
    "# #             print(classifier,\" => \", dataset, \"=>\", end=' ')\n",
    "# #             # tmp_res = clasify(dataset, classifier)\n",
    "# #             # print(tmp_res['auc'])\n",
    "# #             try:\n",
    "# #                 tmp_res = clasify(dataset, classifier)\n",
    "# #                 res_to_files(dataset, classifier, tmp_res)\n",
    "# #             except:\n",
    "# #                 print(dataset, classifier)\n",
    "\n",
    "# classifier = 'Ada1'\n",
    "# for dataset in datasets:\n",
    "#     if not os.path.exists('./Results/'+dataset+'/'+classifier+'/y_pred.npy'):\n",
    "#         print(classifier,\" => \", dataset, \"=>\", end=' ')\n",
    "#         # try:\n",
    "#         tmp_res = clasify(dataset, classifier)\n",
    "#         res_to_files(dataset, classifier, tmp_res)\n",
    "#         # except:\n",
    "#             # print(dataset, classifier)\n",
    "\n",
    "# # classifier = 'AdaCost'\n",
    "# # dataset = 'abalone19-5-'\n",
    "# # if not os.path.exists('./Results/'+dataset+'/'+classifier+'/y_pred.npy'):\n",
    "# #     print(classifier,\" => \", dataset, \"=>\", end=' ')\n",
    "# #     tmp_res = clasify(dataset, classifier)\n",
    "# #     res_to_files(dataset, classifier, tmp_res)\n",
    "# #     print(tmp_res['auc'])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd3c22d-8e51-4549-b055-0166c8ec909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "troubs = {}\n",
    "for classifier in classifiers:\n",
    "    for dataset in datasets:\n",
    "        files = glob.glob('./Results/'+dataset+'/'+classifier+'/*.npy')\n",
    "        if len(files) != 6:\n",
    "            if dataset in troubs:\n",
    "                troubs[dataset].append(classifier)\n",
    "            else:\n",
    "                troubs[dataset] = [classifier]\n",
    "            print(dataset, classifier)\n",
    "        \n",
    "# print([dataset for dataset in troubs if len(troubs[dataset])==4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7c21ce-42ae-4398-8790-6dab0a87c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert categorical variables into numerical\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "# le = LabelEncoder()\n",
    " \n",
    "# # Using .fit_transform function to fit label\n",
    "# # encoder and return encoded label\n",
    "\n",
    "# base_path = 'Datasets/'\n",
    "# need_to_convert = ['abalone19-5-', 'abalone19-5-fold']\n",
    "# for needed in need_to_convert[1:]:\n",
    "#     for datFile in glob.glob(base_path+needed+'/*.dat'):\n",
    "#         print(datFile)\n",
    "#         df = read_dot_dat_file(datFile)\n",
    "#         label = le.fit_transform(df['Sex,'])        \n",
    "#         df['Sex,'] = label\n",
    "#         # df.to_excel(base_path+needed+'/'+datFile.split('/')[-1].split('.')[0]+'.xlsx')\n",
    "#         break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "138cde2d-9c7d-4e61-b733-cb4894e8dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = read_dot_dat_file(glob.glob(base_path+datasets[0]+'/*.dat')[0])\n",
    "# df.to_excel('temp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec1b654-281a-4d72-ba83-ddafec3c725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_excel('temp.xlsx').iloc[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d75001-10b2-4a26-ba28-7ac17700e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yeast-1-2-8-9_vs_7-5-fold RUS\n",
    "# shuttle-c2-vs-c4-5-fold SMOTE\n",
    "# ecoli-0-1-3-7_vs_2-6-5-fold SMOTE\n",
    "# yeast4-5-fold Ada1\n",
    "# abalone19-5- Ada1\n",
    "# abalone19-5-fold Ada1\n",
    "# abalone19-5- AdaCost\n",
    "# abalone19-5-fold AdaCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d7806-0691-4fc2-85b5-c7f6ece4bd29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9720cc5-1b75-4ceb-8194-ca849754cd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
