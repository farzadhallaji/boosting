{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c6ba7c-abf0-4879-8daf-64cf03f708e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c conda-forge imbalanced-learn\n",
    "# ! pip install nose\n",
    "# ! pip install imbalanced-ensemble           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97ceea7-d25a-4b9f-9da9-66198967610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_dot_dat_file(path):\n",
    "    datContent = [i.strip().split() for i in open(path).readlines()]\n",
    "    r = re.compile(\"@inputs.*\")\n",
    "    _at_data = datContent.index(['@data'])\n",
    "    assert datContent[0][0] == '@relation'\n",
    "    assert datContent[_at_data-1][0] == '@outputs'\n",
    "    assert datContent[_at_data-2][0] == '@inputs'\n",
    "    print(datContent[_at_data-3][2:])\n",
    "    assert len(datContent[_at_data-3][2:]) == 2   # Two Class\n",
    "\n",
    "    col_names = datContent[_at_data-2][1:]\n",
    "    col_names.append(datContent[_at_data-1][1])\n",
    "    \n",
    "    df = pd.read_csv(path, skiprows=_at_data+1, names=col_names, sep=r', ', engine='python')\n",
    "    # df = pd.read_csv(path, skiprows=_at_data+1, names=col_names, sep=\", \", engine='python')\n",
    "\n",
    "    class1 = datContent[_at_data-3][2:][0].replace(\"{\",\"\").replace(\",\",\"\")\n",
    "    class2 = datContent[_at_data-3][2:][1].replace(\"}\",\"\").replace(\",\",\"\")\n",
    "\n",
    "    df['Class'] = df['Class'].replace({class1: 1, class2: -1})\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780530b-2810-424b-8feb-0a847faf8ca1",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af89ab8a-ec78-4dbd-a01e-3d02ce85b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# base_path = 'Datasets/'\n",
    "# need_to_convert = ['ecoli-0_vs_1-5-fold','haberman-5-fold','page-blocks0-5-fold','pima-5-fold','vehicle2-5-fold']\n",
    "\n",
    "# for needed in need_to_convert:\n",
    "#     for datFile in os.listdir(base_path+needed):\n",
    "#         print(base_path+needed+'/'+datFile)\n",
    "#         df = read_dot_dat_file(base_path+needed+'/'+datFile)\n",
    "#         df.to_excel(base_path+needed+'/'+datFile.split('.')[0]+'.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c891321f-9db4-46cb-87e0-3d1689692e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import random  \n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc,f1_score,matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imbalanced_ensemble.ensemble import SMOTEBoostClassifier\n",
    "from maatpy.classifiers import AdaCost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6a92d6-54cc-46a5-929a-3918bc55dabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mcc': [-0.056313829183370835,\n",
       "  -0.056313829183370835,\n",
       "  0.19936606554975947,\n",
       "  0.23095609134944634,\n",
       "  0.7132259743375],\n",
       " 'auc': [0.47674418604651164,\n",
       "  0.47674418604651164,\n",
       "  0.5717054263565892,\n",
       "  0.6317829457364341,\n",
       "  0.8274509803921568],\n",
       " 'f1': [0.0, 0.0, 0.2222222222222222, 0.28571428571428575, 0.7272727272727272],\n",
       " 'gmean': [0.0,\n",
       "  0.0,\n",
       "  0.4034732923929645,\n",
       "  0.5568460463897045,\n",
       "  0.8116794499134278],\n",
       " 'exe_time': [0.030020475387573242,\n",
       "  0.02517867088317871,\n",
       "  0.016266822814941406,\n",
       "  0.021300792694091797,\n",
       "  0.02183365821838379],\n",
       " 'y_pred': array([-1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1,  1,  1, -1,  1,  1])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = 'Datasets/'\n",
    "datasets  = os.listdir(base_path) \n",
    "classifiers = {\"RUS\": RUSBoostClassifier(random_state=0, algorithm='SAMME', estimator=DecisionTreeClassifier(max_depth=10)),\n",
    "              \"SMOTE\": SMOTEBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10), n_estimators = 100, algorithm='SAMME', random_state=0),\n",
    "              \"Ada1\": AdaCost(base_estimator=DecisionTreeClassifier(max_depth=10), n_estimators=100, algorithm='adac1',random_state=0),\n",
    "              \"AdaCost\": AdaCost(base_estimator=DecisionTreeClassifier(max_depth=10), n_estimators=100, algorithm='adacost',random_state=0),}\n",
    "\n",
    "\n",
    "def clasify(dataset, classifier):\n",
    "    mcc = []\n",
    "    f1 = []\n",
    "    auc_a = []\n",
    "    gmean = []\n",
    "    times = []\n",
    "    y_preds = []\n",
    "    traFiles = sorted(glob.glob(base_path+dataset+'/*tra.xlsx'))\n",
    "    tstFiles = sorted(glob.glob(base_path+dataset+'/*tst.xlsx'))\n",
    "    for traPath, tstPath in zip(traFiles, tstFiles):\n",
    "        # print(traPath)\n",
    "        \n",
    "        df_train = pd.read_excel(traPath)\n",
    "        df_test = pd.read_excel(tstPath)\n",
    "\n",
    "        x_train= df_train.iloc[:, 0:-1]\n",
    "        y_train = df_train.iloc[:, -1]\n",
    "        x_test= df_test.iloc[:, 0:-1]\n",
    "        y_test = df_test.iloc[:, -1]\n",
    "        \n",
    "        #####\n",
    "        # for some dataset get error Unknown label type: 'unknown'\n",
    "        y_train = y_train.astype('int')\n",
    "        y_test = y_test.astype('int')\n",
    "        \n",
    "        st = time.time()\n",
    "        clf = classifiers[classifier]\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(x_test) \n",
    "        et = time.time()\n",
    "        y_preds.append(y_pred)\n",
    "        # compute error\n",
    "        mcc.append(matthews_corrcoef(y_test, y_pred))\n",
    "        #--------------------------------\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "        auc_a.append(auc(fpr, tpr))\n",
    "        #--------------------------------\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        #--------------------------------\n",
    "        gmean.append(geometric_mean_score(y_test, y_pred, labels=[1, -1]))\n",
    "        \n",
    "        #time of train and test\n",
    "        times.append(et - st)\n",
    "        \n",
    "    return {\"mcc\": mcc, \"auc\": auc_a, \"f1\": f1, \"gmean\": gmean, \"exe_time\": times, \"y_pred\": y_pred}\n",
    "\n",
    "aaaaaa =  clasify(datasets[0], 'Ada1')\n",
    "aaaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f0a8692-aeb2-4fcd-a2d8-bc54829958fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #temp \n",
    "# for i in range(1,len(datasets)):\n",
    "#     os.mkdir('./Results/'+datasets[i])\n",
    "#     # print(os.path.isdir('./Results/'+datasets[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e88568-2e7f-473c-b2a4-e2737994cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_files(dataset, dict_res):\n",
    "    np.save('./Results/'+dataset+'/mcc.npy',dict_res['mcc'])\n",
    "    np.save('./Results/'+dataset+'/auc.npy',dict_res['auc'])\n",
    "    np.save('./Results/'+dataset+'/gmean.npy',dict_res['gmean'])\n",
    "    np.save('./Results/'+dataset+'/exe_time.npy',dict_res['exe_time'])\n",
    "    np.save('./Results/'+dataset+'/y_pred.npy',dict_res['y_pred'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be00f465-4b1a-42e6-a951-9c7dc485764a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold\n",
      "ecoli-0-3-4-6_vs_5-5-fold\n",
      "abalone19-5-fold\n",
      "led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold\n",
      "ecoli-0-3-4-6_vs_5-5-fold\n",
      "abalone19-5-fold\n",
      "led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold\n",
      "ecoli-0-3-4-6_vs_5-5-fold\n",
      "abalone19-5-fold\n",
      "led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold\n",
      "ecoli-0-3-4-6_vs_5-5-fold\n",
      "abalone19-5-fold\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    for dataset in datasets:\n",
    "        if not os.path.exists('./Results/'+dataset+'/y_pred.npy'):\n",
    "            try:\n",
    "                tmp_res = clasify(dataset, classifier)\n",
    "                res_to_files(dataset, tmp_res)\n",
    "            except:\n",
    "                print(dataset)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c0efd-987e-4dfb-ad61-2859080fc3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
