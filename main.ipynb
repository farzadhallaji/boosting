{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6ba7c-abf0-4879-8daf-64cf03f708e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c conda-forge imbalanced-learn -y\n",
    "# ! pip install nose\n",
    "# ! pip install imbalanced-ensemble           \n",
    "# ! pip install threadpoolctl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97ceea7-d25a-4b9f-9da9-66198967610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_dot_dat_file(path):\n",
    "    datContent = [i.strip().split() for i in open(path).readlines()]\n",
    "    r = re.compile(\"@inputs.*\")\n",
    "    _at_data = datContent.index(['@data'])\n",
    "    assert datContent[0][0] == '@relation'\n",
    "    assert datContent[_at_data-1][0] == '@outputs'\n",
    "    assert datContent[_at_data-2][0] == '@inputs'\n",
    "    print(datContent[_at_data-3][2:])\n",
    "    assert len(datContent[_at_data-3][2:]) == 2   # Two Class\n",
    "\n",
    "    col_names = datContent[_at_data-2][1:]\n",
    "    col_names.append(datContent[_at_data-1][1])\n",
    "    \n",
    "    df = pd.read_csv(path, skiprows=_at_data+1, names=col_names, sep=r', ', engine='python')\n",
    "    # df = pd.read_csv(path, skiprows=_at_data+1, names=col_names, sep=\", \", engine='python')\n",
    "\n",
    "    class1 = datContent[_at_data-3][2:][0].replace(\"{\",\"\").replace(\",\",\"\")\n",
    "    class2 = datContent[_at_data-3][2:][1].replace(\"}\",\"\").replace(\",\",\"\")\n",
    "\n",
    "    df['Class'] = df['Class'].replace({class1: 1, class2: -1})\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780530b-2810-424b-8feb-0a847faf8ca1",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af89ab8a-ec78-4dbd-a01e-3d02ce85b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# base_path = 'Datasets/'\n",
    "# # need_to_convert = ['wisconsin-5-fold','new-thyroid2-5-fold','new-thyroid1-5-fold']\n",
    "# # need_to_convert = ['yeast-1_vs_7-5-fold', 'led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold', 'ecoli-0-3-4-6_vs_5-5-fold', 'abalone19-5-', 'abalone19-5-fold']\n",
    "# # need_to_convert = ['ecoli-0-1_vs_5-5-fold','ecoli-0-1-4-7_vs_5-6-5-fold','ecoli-0-3-4-7_vs_5-6-5-fold','glass-0-1-4-6_vs_2-5-fold', 'ecoli-0-4-6_vs_5-5-fold',\n",
    "# #                   'yeast-0-3-5-9_vs_7-8-5-fold','yeast-1-2-8-9_vs_7-5-fold']\n",
    "# need_to_convert = ['yeast-1-2-8-9_vs_7-5-fold']\n",
    "# for needed in need_to_convert:\n",
    "#     for datFile in glob.glob(base_path+needed+'/*.dat'):\n",
    "#         print(datFile)\n",
    "#         df = read_dot_dat_file(datFile)\n",
    "#         df.to_excel(base_path+needed+'/'+datFile.split('/')[-1].split('.')[0]+'.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c891321f-9db4-46cb-87e0-3d1689692e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6a92d6-54cc-46a5-929a-3918bc55dabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/yeast4-5-fold/yeast4-5-1tra.xlsx\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1146 (1147, 7)\n",
      "indexs.max(), X_maj.shape 32 (1147, 7)\n",
      "indexs.max(), X_maj.shape 1339 (1147, 7)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1269 is out of bounds for axis 0 with size 1147",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1470877fe44e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# aaaaaa =  clasify('yeast-1-2-8-9_vs_7-5-fold', 'RUS')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m# aaaaaa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mclasify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yeast4-5-fold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OUBoost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-1470877fe44e>\u001b[0m in \u001b[0;36mclasify\u001b[0;34m(dataset, classifier)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Boost/OUBoost.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, minority_target)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'indexs.max(), X_maj.shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_maj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0mX_rus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_maj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_maj\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminority_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1269 is out of bounds for axis 0 with size 1147"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import random  \n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc,f1_score, matthews_corrcoef, precision_score, recall_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imbalanced_ensemble.ensemble import SMOTEBoostClassifier\n",
    "from maatpy.classifiers import AdaCost\n",
    "\n",
    "from OUBoost import OUBoost\n",
    "\n",
    "base_path = 'Datasets/'\n",
    "datasets  = os.listdir(base_path) \n",
    "classifiers = {\"RUS\": RUSBoostClassifier(random_state=0, algorithm='SAMME', base_estimator=DecisionTreeClassifier(max_depth=10)),\n",
    "              \"SMOTE\": SMOTEBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=10), n_estimators = 100, algorithm='SAMME', random_state=0),\n",
    "              \"Ada1\": AdaCost(base_estimator=DecisionTreeClassifier(max_depth=10), n_estimators=100, algorithm='adac1',random_state=0),\n",
    "              \"AdaCost\": AdaCost(base_estimator=DecisionTreeClassifier(max_depth=10), n_estimators=100, algorithm='adacost',random_state=0),\n",
    "              \"OUBoost\": OUBoost(learning_rate=0.3, n_samples=100, n_estimators=100)}\n",
    "            \n",
    "\n",
    "def clasify(dataset, classifier):\n",
    "    mcc = []\n",
    "    f1 = []\n",
    "    auc_a = []\n",
    "    gmean = []\n",
    "    times = []\n",
    "    y_preds = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    traFiles = sorted(glob.glob(base_path+dataset+'/*tra.xlsx'))\n",
    "    tstFiles = sorted(glob.glob(base_path+dataset+'/*tst.xlsx'))\n",
    "    for traPath, tstPath in zip(traFiles, tstFiles):\n",
    "        print(traPath)\n",
    "        \n",
    "        df_train = pd.read_excel(traPath)\n",
    "        df_test = pd.read_excel(tstPath)\n",
    "\n",
    "        x_train= df_train.iloc[:, 1:-1]\n",
    "        y_train = df_train.iloc[:, -1]\n",
    "        x_test= df_test.iloc[:, 1:-1]\n",
    "        y_test = df_test.iloc[:, -1]\n",
    "        \n",
    "        #####\n",
    "        # for some dataset get error Unknown label type: 'unknown'\n",
    "        y_train = y_train.astype('int')\n",
    "        y_test = y_test.astype('int')\n",
    "        \n",
    "        st = time.time()\n",
    "        clf = classifiers[classifier]\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(x_test) \n",
    "        et = time.time()\n",
    "        y_preds.append(y_pred)\n",
    "        # compute error\n",
    "        mcc.append(matthews_corrcoef(y_test, y_pred))\n",
    "        #--------------------------------\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "        auc_a.append(auc(fpr, tpr))\n",
    "        #--------------------------------\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        #--------------------------------\n",
    "        gmean.append(geometric_mean_score(y_test, y_pred, labels=[1, -1]))\n",
    "        \n",
    "        #time of train and test\n",
    "        times.append(et - st)\n",
    "        \n",
    "        precisions.append(precision_score(y_test, y_pred))\n",
    "        recalls.append(precision_score(y_test, y_pred))\n",
    "        \n",
    "    return {\"precision\": precisions, \"recall\": recalls, \"mcc\": mcc, \"auc\": auc_a, \"f1\": f1, \"gmean\": gmean, \"exe_time\": times, \"y_pred\": y_pred}\n",
    "\n",
    "# aaaaaa =  clasify(datasets[0], 'Ada1')\n",
    "# aaaaaa =  clasify('yeast-1-2-8-9_vs_7-5-fold', 'RUS')\n",
    "# aaaaaa\n",
    "clasify('yeast4-5-fold', 'OUBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9f0a8692-aeb2-4fcd-a2d8-bc54829958fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #temp \n",
    "# for i in range(len(datasets)):\n",
    "#     if not os.path.isdir('./Results/'+datasets[i]):\n",
    "#         os.mkdir('./Results/'+datasets[i])\n",
    "#     for classifier in classifiers:\n",
    "#         if not os.path.isdir('./Results/'+datasets[i]+'/'+classifier):\n",
    "#             os.mkdir('./Results/'+datasets[i]+'/'+classifier)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e88568-2e7f-473c-b2a4-e2737994cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_files(dataset, classifier, dict_res):\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/mcc.npy',dict_res['mcc'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/auc.npy',dict_res['auc'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/f1.npy',dict_res['f1'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/gmean.npy',dict_res['gmean'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/exe_time.npy',dict_res['exe_time'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/y_pred.npy',dict_res['y_pred'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f9ec686-ac23-4236-ba0e-47c56c1cb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00f465-4b1a-42e6-a951-9c7dc485764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for classifier in classifiers:\n",
    "#     for dataset in datasets:\n",
    "#         if not os.path.exists('./Results/'+dataset+'/'+classifier+'/y_pred.npy'):\n",
    "#             print(classifier,\" => \", dataset, \"=>\", end=' ')\n",
    "#             # tmp_res = clasify(dataset, classifier)\n",
    "#             # print(tmp_res['auc'])\n",
    "#             try:\n",
    "#                 tmp_res = clasify(dataset, classifier)\n",
    "#                 res_to_files(dataset, classifier, tmp_res)\n",
    "#             except:\n",
    "#                 print(dataset, classifier)\n",
    "\n",
    "classifier = 'Ada1'\n",
    "for dataset in datasets:\n",
    "    if not os.path.exists('./Results/'+dataset+'/'+classifier+'/y_pred.npy'):\n",
    "        print(classifier,\" => \", dataset, \"=>\", end=' ')\n",
    "        # try:\n",
    "        tmp_res = clasify(dataset, classifier)\n",
    "        res_to_files(dataset, classifier, tmp_res)\n",
    "        # except:\n",
    "            # print(dataset, classifier)\n",
    "\n",
    "# classifier = 'AdaCost'\n",
    "# dataset = 'abalone19-5-'\n",
    "# if not os.path.exists('./Results/'+dataset+'/'+classifier+'/y_pred.npy'):\n",
    "#     print(classifier,\" => \", dataset, \"=>\", end=' ')\n",
    "#     tmp_res = clasify(dataset, classifier)\n",
    "#     res_to_files(dataset, classifier, tmp_res)\n",
    "#     print(tmp_res['auc'])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd3c22d-8e51-4549-b055-0166c8ec909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "troubs = {}\n",
    "for classifier in classifiers:\n",
    "    for dataset in datasets:\n",
    "        files = glob.glob('./Results/'+dataset+'/'+classifier+'/*.npy')\n",
    "        if len(files) != 6:\n",
    "            if dataset in troubs:\n",
    "                troubs[dataset].append(classifier)\n",
    "            else:\n",
    "                troubs[dataset] = [classifier]\n",
    "            print(dataset, classifier)\n",
    "        \n",
    "# print([dataset for dataset in troubs if len(troubs[dataset])==4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7c21ce-42ae-4398-8790-6dab0a87c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert categorical variables into numerical\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "# le = LabelEncoder()\n",
    " \n",
    "# # Using .fit_transform function to fit label\n",
    "# # encoder and return encoded label\n",
    "\n",
    "# base_path = 'Datasets/'\n",
    "# need_to_convert = ['abalone19-5-', 'abalone19-5-fold']\n",
    "# for needed in need_to_convert[1:]:\n",
    "#     for datFile in glob.glob(base_path+needed+'/*.dat'):\n",
    "#         print(datFile)\n",
    "#         df = read_dot_dat_file(datFile)\n",
    "#         label = le.fit_transform(df['Sex,'])        \n",
    "#         df['Sex,'] = label\n",
    "#         # df.to_excel(base_path+needed+'/'+datFile.split('/')[-1].split('.')[0]+'.xlsx')\n",
    "#         break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "138cde2d-9c7d-4e61-b733-cb4894e8dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = read_dot_dat_file(glob.glob(base_path+datasets[0]+'/*.dat')[0])\n",
    "# df.to_excel('temp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec1b654-281a-4d72-ba83-ddafec3c725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_excel('temp.xlsx').iloc[:, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d75001-10b2-4a26-ba28-7ac17700e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yeast-1-2-8-9_vs_7-5-fold RUS\n",
    "# shuttle-c2-vs-c4-5-fold SMOTE\n",
    "# ecoli-0-1-3-7_vs_2-6-5-fold SMOTE\n",
    "# yeast4-5-fold Ada1\n",
    "# abalone19-5- Ada1\n",
    "# abalone19-5-fold Ada1\n",
    "# abalone19-5- AdaCost\n",
    "# abalone19-5-fold AdaCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d7806-0691-4fc2-85b5-c7f6ece4bd29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9720cc5-1b75-4ceb-8194-ca849754cd2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
