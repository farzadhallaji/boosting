{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c6ba7c-abf0-4879-8daf-64cf03f708e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -c conda-forge imbalanced-learn\n",
    "# ! pip install nose\n",
    "# ! pip install imbalanced-ensemble           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97ceea7-d25a-4b9f-9da9-66198967610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_dot_dat_file(path):\n",
    "    datContent = [i.strip().split() for i in open(path).readlines()]\n",
    "    r = re.compile(\"@inputs.*\")\n",
    "    _at_data = datContent.index(['@data'])\n",
    "    assert datContent[0][0] == '@relation'\n",
    "    assert datContent[_at_data-1][0] == '@outputs'\n",
    "    assert datContent[_at_data-2][0] == '@inputs'\n",
    "    print(datContent[_at_data-3][2:])\n",
    "    assert len(datContent[_at_data-3][2:]) == 2   # Two Class\n",
    "\n",
    "    col_names = datContent[_at_data-2][1:]\n",
    "    col_names.append(datContent[_at_data-1][1])\n",
    "    \n",
    "    df = pd.read_csv(path, skiprows=_at_data+1, names=col_names, sep=r', ', engine='python')\n",
    "    # df = pd.read_csv(path, skiprows=_at_data+1, names=col_names, sep=\", \", engine='python')\n",
    "\n",
    "    class1 = datContent[_at_data-3][2:][0].replace(\"{\",\"\").replace(\",\",\"\")\n",
    "    class2 = datContent[_at_data-3][2:][1].replace(\"}\",\"\").replace(\",\",\"\")\n",
    "\n",
    "    df['Class'] = df['Class'].replace({class1: 1, class2: -1})\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780530b-2810-424b-8feb-0a847faf8ca1",
   "metadata": {},
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af89ab8a-ec78-4dbd-a01e-3d02ce85b6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets/abalone19-5-fold/abalone19-5-5tst.dat\n",
      "['{positive,', 'negative}']\n",
      "Datasets/abalone19-5-fold/abalone19-5-2tst.dat\n",
      "['{positive,', 'negative}']\n",
      "Datasets/abalone19-5-fold/abalone19-5-4tst.dat\n",
      "['{positive,', 'negative}']\n",
      "Datasets/abalone19-5-fold/abalone19-5-1tst.dat\n",
      "['{positive,', 'negative}']\n",
      "Datasets/abalone19-5-fold/abalone19-5-2tra.dat\n",
      "['{positive,', 'negative}']\n",
      "Datasets/abalone19-5-fold/abalone19-5-1tra.dat\n",
      "['{positive,', 'negative}']\n",
      "Datasets/abalone19-5-fold/abalone19-5-3tra.dat\n",
      "['{positive,', 'negative}']\n",
      "Datasets/abalone19-5-fold/abalone19-5-5tra.dat\n",
      "['{positive,', 'negative}']\n",
      "Datasets/abalone19-5-fold/abalone19-5-3tst.dat\n",
      "['{positive,', 'negative}']\n",
      "Datasets/abalone19-5-fold/abalone19-5-4tra.dat\n",
      "['{positive,', 'negative}']\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd \n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# base_path = 'Datasets/'\n",
    "# # need_to_convert = ['wisconsin-5-fold','new-thyroid2-5-fold','new-thyroid1-5-fold']\n",
    "# need_to_convert = ['yeast-1_vs_7-5-fold', 'led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold', 'ecoli-0-3-4-6_vs_5-5-fold', 'abalone19-5-', 'abalone19-5-fold']\n",
    "# for needed in need_to_convert[4:]:\n",
    "#     for datFile in glob.glob(base_path+needed+'/*.dat'):\n",
    "#         print(datFile)\n",
    "#         df = read_dot_dat_file(datFile)\n",
    "#         df.to_excel(base_path+needed+'/'+datFile.split('/')[-1].split('.')[0]+'.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c891321f-9db4-46cb-87e0-3d1689692e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import random  \n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc,f1_score,matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imbalanced_ensemble.ensemble import SMOTEBoostClassifier\n",
    "from maatpy.classifiers import AdaCost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f6a92d6-54cc-46a5-929a-3918bc55dabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mcc': [-0.056313829183370835,\n",
       "  -0.056313829183370835,\n",
       "  0.19936606554975947,\n",
       "  0.23095609134944634,\n",
       "  0.7132259743375],\n",
       " 'auc': [0.47674418604651164,\n",
       "  0.47674418604651164,\n",
       "  0.5717054263565892,\n",
       "  0.6317829457364341,\n",
       "  0.8274509803921568],\n",
       " 'f1': [0.0, 0.0, 0.2222222222222222, 0.28571428571428575, 0.7272727272727272],\n",
       " 'gmean': [0.0,\n",
       "  0.0,\n",
       "  0.4034732923929645,\n",
       "  0.5568460463897045,\n",
       "  0.8116794499134278],\n",
       " 'exe_time': [0.02290058135986328,\n",
       "  0.024185895919799805,\n",
       "  0.013829946517944336,\n",
       "  0.020322799682617188,\n",
       "  0.011529684066772461],\n",
       " 'y_pred': array([-1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1,  1,  1, -1,  1,  1])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = 'Datasets/'\n",
    "datasets  = os.listdir(base_path) \n",
    "classifiers = {\"RUS\": RUSBoostClassifier(random_state=0, algorithm='SAMME', estimator=DecisionTreeClassifier(max_depth=10)),\n",
    "              \"SMOTE\": SMOTEBoostClassifier(estimator=DecisionTreeClassifier(max_depth=10), n_estimators = 100, algorithm='SAMME', random_state=0),\n",
    "              \"Ada1\": AdaCost(base_estimator=DecisionTreeClassifier(max_depth=10), n_estimators=100, algorithm='adac1',random_state=0),\n",
    "              \"AdaCost\": AdaCost(base_estimator=DecisionTreeClassifier(max_depth=10), n_estimators=100, algorithm='adacost',random_state=0),}\n",
    "\n",
    "\n",
    "def clasify(dataset, classifier):\n",
    "    mcc = []\n",
    "    f1 = []\n",
    "    auc_a = []\n",
    "    gmean = []\n",
    "    times = []\n",
    "    y_preds = []\n",
    "    traFiles = sorted(glob.glob(base_path+dataset+'/*tra.xlsx'))\n",
    "    tstFiles = sorted(glob.glob(base_path+dataset+'/*tst.xlsx'))\n",
    "    for traPath, tstPath in zip(traFiles, tstFiles):\n",
    "        # print(traPath)\n",
    "        \n",
    "        df_train = pd.read_excel(traPath)\n",
    "        df_test = pd.read_excel(tstPath)\n",
    "\n",
    "        x_train= df_train.iloc[:, 0:-1]\n",
    "        y_train = df_train.iloc[:, -1]\n",
    "        x_test= df_test.iloc[:, 0:-1]\n",
    "        y_test = df_test.iloc[:, -1]\n",
    "        \n",
    "        #####\n",
    "        # for some dataset get error Unknown label type: 'unknown'\n",
    "        y_train = y_train.astype('int')\n",
    "        y_test = y_test.astype('int')\n",
    "        \n",
    "        st = time.time()\n",
    "        clf = classifiers[classifier]\n",
    "\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(x_test) \n",
    "        et = time.time()\n",
    "        y_preds.append(y_pred)\n",
    "        # compute error\n",
    "        mcc.append(matthews_corrcoef(y_test, y_pred))\n",
    "        #--------------------------------\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "        auc_a.append(auc(fpr, tpr))\n",
    "        #--------------------------------\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        #--------------------------------\n",
    "        gmean.append(geometric_mean_score(y_test, y_pred, labels=[1, -1]))\n",
    "        \n",
    "        #time of train and test\n",
    "        times.append(et - st)\n",
    "        \n",
    "    return {\"mcc\": mcc, \"auc\": auc_a, \"f1\": f1, \"gmean\": gmean, \"exe_time\": times, \"y_pred\": y_pred}\n",
    "\n",
    "aaaaaa =  clasify(datasets[0], 'Ada1')\n",
    "aaaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f0a8692-aeb2-4fcd-a2d8-bc54829958fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #temp \n",
    "for i in range(1,len(datasets)):\n",
    "    if not os.path.isdir('./Results/'+datasets[i]):\n",
    "        os.mkdir('./Results/'+datasets[i])\n",
    "    for classifier in classifiers:\n",
    "        if not os.path.isdir('./Results/'+datasets[i]+'/'+classifier):\n",
    "            os.mkdir('./Results/'+datasets[i]+'/'+classifier)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4e88568-2e7f-473c-b2a4-e2737994cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_files(dataset, classifier, dict_res):\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/mcc.npy',dict_res['mcc'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/auc.npy',dict_res['auc'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/f1.npy',dict_res['f1'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/gmean.npy',dict_res['gmean'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/exe_time.npy',dict_res['exe_time'])\n",
    "    np.save('./Results/'+dataset+'/'+classifier+'/y_pred.npy',dict_res['y_pred'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00f465-4b1a-42e6-a951-9c7dc485764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier in classifiers:\n",
    "    for dataset in datasets:\n",
    "        if not os.path.exists('./Results/'+dataset+'/y_pred.npy'):\n",
    "            print(classifier,\" => \", dataset, \"=>\", end=' ')\n",
    "            # tmp_res = clasify(dataset, classifier)\n",
    "            # print(tmp_res['auc'])\n",
    "            try:\n",
    "                tmp_res = clasify(dataset, classifier)\n",
    "                res_to_files(dataset, classifier, tmp_res)\n",
    "            except:\n",
    "                print(dataset, classifier)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb3c0efd-987e-4dfb-ad61-2859080fc3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "troubs = {}\n",
    "troubs['s']= 0\n",
    "'s' in troubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4dd3c22d-8e51-4549-b055-0166c8ec909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeast-1_vs_7-5-fold RUS\n",
      "yeast-1_vs_7-5-fold SMOTE\n",
      "yeast-1_vs_7-5-fold Ada1\n",
      "yeast-1_vs_7-5-fold AdaCost\n",
      "led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold RUS\n",
      "led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold SMOTE\n",
      "led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold Ada1\n",
      "led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold AdaCost\n",
      "ecoli-0-3-4-6_vs_5-5-fold RUS\n",
      "ecoli-0-3-4-6_vs_5-5-fold SMOTE\n",
      "ecoli-0-3-4-6_vs_5-5-fold Ada1\n",
      "ecoli-0-3-4-6_vs_5-5-fold AdaCost\n",
      "ecoli-0-1-4-6_vs_5-5-fold RUS\n",
      "ecoli-0-1-4-6_vs_5-5-fold SMOTE\n",
      "shuttle-c2-vs-c4-5-fold SMOTE\n",
      "ecoli-0-1_vs_5-5-fold RUS\n",
      "ecoli-0-1_vs_5-5-fold SMOTE\n",
      "abalone19-5- RUS\n",
      "abalone19-5- SMOTE\n",
      "abalone19-5- Ada1\n",
      "abalone19-5- AdaCost\n",
      "ecoli-0-1-4-7_vs_5-6-5-fold RUS\n",
      "ecoli-0-1-4-7_vs_5-6-5-fold SMOTE\n",
      "ecoli-0-3-4-7_vs_5-6-5-fold RUS\n",
      "ecoli-0-3-4-7_vs_5-6-5-fold SMOTE\n",
      "ecoli-0-1-3-7_vs_2-6-5-fold SMOTE\n",
      "glass-0-1-4-6_vs_2-5-fold RUS\n",
      "glass-0-1-4-6_vs_2-5-fold SMOTE\n",
      "abalone19-5-fold RUS\n",
      "abalone19-5-fold SMOTE\n",
      "abalone19-5-fold Ada1\n",
      "abalone19-5-fold AdaCost\n",
      "ecoli-0-4-6_vs_5-5-fold RUS\n",
      "ecoli-0-4-6_vs_5-5-fold SMOTE\n",
      "yeast-0-3-5-9_vs_7-8-5-fold RUS\n",
      "yeast-0-3-5-9_vs_7-8-5-fold SMOTE\n",
      "yeast-1-2-8-9_vs_7-5-fold RUS\n",
      "['yeast-1_vs_7-5-fold', 'led7digit-0-2-4-5-6-7-8-9_vs_1-5-fold', 'ecoli-0-3-4-6_vs_5-5-fold', 'abalone19-5-', 'abalone19-5-fold']\n"
     ]
    }
   ],
   "source": [
    "troubs = {}\n",
    "for dataset in datasets:\n",
    "    for classifier in classifiers:\n",
    "        files = glob.glob('./Results/'+dataset+'/'+classifier+'/*.npy')\n",
    "        if len(files) != 6:\n",
    "            if dataset in troubs:\n",
    "                troubs[dataset].append(classifier)\n",
    "            else:\n",
    "                troubs[dataset] = [classifier]\n",
    "            print(dataset, classifier)\n",
    "        \n",
    "print([dataset for dataset in troubs if len(troubs[dataset])==4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
